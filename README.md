# Desafio - CiÃªncia de Dados

## Objetivo

Neste desafio, realizamos a anÃ¡lise e transformaÃ§Ã£o dos dados do arquivo `dados_ficha_a_desafio.csv`, identificando problemas e aplicando tratamentos adequados com DBT.

---

## Tarefas

### 1. ExploraÃ§Ã£o e apontamento de problemas
- Analisamos cada campo do dataset, identificando padrÃµes e inconsistÃªncias.
- Apontamos possÃ­veis problemas e inferimos hipÃ³teses sobre a origem dessas questÃµes.
- Documentamos questionamentos relevantes para melhor compreensÃ£o dos dados.

### 2. Tratamento de dados com DBT
- Criamos um modelo DBT para padronizar os dados e gerar uma tabela tratada.
- Aplicamos boas prÃ¡ticas para garantir modularizaÃ§Ã£o e legibilidade do cÃ³digo.

---

## Como rodar o projeto

O projeto utiliza o gerenciador de pacotes [Poetry](https://python-poetry.org/) para instalar dependÃªncias. Embora o uso do Poetry nÃ£o seja obrigatÃ³rio, ele facilita a organizaÃ§Ã£o e o gerenciamento das bibliotecas. Atualmente, foi utilizada a versÃ£o `2.0.1`, mas versÃµes anteriores, como `1.8.4`, tambÃ©m funcionam, com a diferenÃ§a de que, apÃ³s a instalaÃ§Ã£o das dependÃªncias, Ã© necessÃ¡rio ativar o ambiente virtual manualmente via `poetry shell`.

### Passo a passo para execuÃ§Ã£o
1. **Coloque o arquivo de dados original no diretÃ³rio** `data/raw/`.
2. **Instale as dependÃªncias do projeto**:
   ```bash
   poetry install
   ```
3. **Executar os scripts:**
   - Para abrir um Jupyter Notebook com anotaÃ§Ãµes detalhadas:
     ```bash
     poetry run jupyter lab
     ```
   - Para executar o prÃ©-processamento dos dados diretamente:
     ```bash
     poetry run python src/preprocessing.py
     ```

Caso prefira usar `pip`, o arquivo `requirements.txt` estÃ¡ atualizado. Para gerar um novo `requirements.txt` apÃ³s adicionar dependÃªncias:
```bash
poetry run pip freeze > requirements.txt
```

---

## AnÃ¡lises

Para explorar o dataset transformado, siga as etapas anteriores para gerar o arquivo `.csv` tratado e, em seguida, execute o notebook `notebooks/eda.ipynb`. 

> **Nota:** O notebook estÃ¡ sem execuÃ§Ã£o prÃ©via (`clear output`) para evitar exposiÃ§Ã£o dos dados.

---

## DBT

Para preparar o ambiente de banco de dados, utilizamos **Docker**. Antes de executar os comandos a seguir, certifique-se de ter o **Docker** instalado.

1. **Subir o container do banco de dados**:
   ```bash
   docker-compose up -d
   ```
2. **Inicializar o banco de dados com os dados originais**:
   ```bash
   poetry run python src/dbt_init.py
   ```
3. **Testar a conexÃ£o do DBT com o banco**:
   ```bash
   cd dbt_project
   poetry run dbt debug
   ```
4. **Executar as transformaÃ§Ãµes no DBT**:
   ```bash
   cd dbt_project
   poetry run dbt run
   ```

### LimitaÃ§Ãµes encontradas
O DBT foi utilizado para estruturar e transformar os dados no **PostgreSQL**, porÃ©m algumas transformaÃ§Ãµes complexas (como tratamento de colunas multivaloradas) se mostraram consideravelmente problemÃ¡ticas em SQL. Em particular, a divisÃ£o de certos campos foi parcialmente implementada, mas a abordagem completa exigiria transformaÃ§Ãµes mais elaboradas, tornando o cÃ³digo menos eficiente e difÃ­cil de manter. 

Como alternativa, foi verificado online a possibilidade de usar DBT com **Python**, que permitiria reutilizar parte das transformaÃ§Ãµes feitas anteriormente em Pandas, e para alguns adaptadores de DBT isso pode ser feito.

---

## Tecnologias utilizadas
- **Python** para anÃ¡lise exploratÃ³ria e prÃ©-processamento.
- **SQL** para manipulaÃ§Ã£o dos dados.
- **DBT** (Data Build Tool) para transformaÃ§Ã£o e modelagem dos dados.
- **Docker** para gerenciamento do banco de dados.

---

## Estrutura do RepositÃ³rio
```
ğŸ“¦ desafio-ciencia-dados
â”£ ğŸ“‚ data/           â†’ Local para armazenar os dados brutos e tratados.
â”£ ğŸ“‚ notebooks/      â†’ Notebooks de anÃ¡lise exploratÃ³ria.
â”£ ğŸ“‚ dbt_project/    â†’ Arquivos de configuraÃ§Ã£o e modelos do DBT.
â”£ ğŸ“‚ src/            â†’ Scripts Python utilizados no projeto.
â”£ ğŸ“œ README.md       â†’ DocumentaÃ§Ã£o principal do projeto.
```
